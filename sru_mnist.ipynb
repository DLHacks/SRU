{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "\n",
    "cuda_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' データセットの準備 '''\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# yをone-hot表現に\n",
    "# y_train = np_utils.to_categorical(y_train)\n",
    "# y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "# x, yの型変換\n",
    "X_train, X_test = X_train.astype('float32'), X_test.astype('float32')\n",
    "y_train, y_test = y_train.astype('int64'), y_test.astype('int64')\n",
    "\n",
    "# xの範囲を[0, 1]に変換\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# 2次元の画像を、各行を互い違いにして1次元に変換\n",
    "def flatten_img(images):\n",
    "    '''\n",
    "    images: shape => (n, rows, columns)\n",
    "    output: shape => (n, rows*columns)\n",
    "    '''\n",
    "    n_rows    = images.shape[1]\n",
    "    n_columns = images.shape[2]\n",
    "    for num in range(n_rows):\n",
    "        if num % 2 != 0:\n",
    "            images[:, num, :] = images[:, num, :][:, ::-1]\n",
    "    output = images.reshape(-1, n_rows*n_columns)\n",
    "    return output\n",
    "\n",
    "X_train, X_test = flatten_img(X_train), flatten_img(X_test)\n",
    "\n",
    "# X.shape => (n_sample, seq_size, n_features) に変換\n",
    "X_train, X_test = X_train[:, :, np.newaxis], X_test[:, :, np.newaxis]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' SRUモデルの定義 '''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class SRU(nn.Module):\n",
    "    def __init__(self, x_dim, phi_dim, r_dim, o_dim, A, GPU=True):\n",
    "        \"\"\" \n",
    "        x_dim:   入力xの次元（特徴量数）\n",
    "        phi_dim: phiの次元。\\mu^{\\alpha}の次元とも等しい\n",
    "        r_dim:   rの次元\n",
    "        o_dim:   出力oの次元\n",
    "        A:       [\\alpha_1, \\alpha_2, ..., \\alpha_m], shape: (1, m)\n",
    "        \"\"\"\n",
    "\n",
    "        super(SRU, self).__init__()\n",
    "\n",
    "        self.gpu     = GPU\n",
    "        n_alpha      = A.size()[1]\n",
    "        self.n_alpha = n_alpha\n",
    "        self.A       = A\n",
    "        self.phi_dim = phi_dim\n",
    "        # muの次元 = phiの次元*alphaの個数\n",
    "        mu_dim = phi_dim * n_alpha \n",
    "        self.mu_dim = mu_dim\n",
    "        \n",
    "        # 各結合の定義\n",
    "        self.mu2r    = nn.Linear(mu_dim, r_dim)\n",
    "        self.xr2phi  = nn.Linear(x_dim + r_dim, phi_dim)\n",
    "        self.mu2o    = nn.Linear(mu_dim, o_dim)\n",
    "        self.log_softmax = nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, x, mu):\n",
    "        '''\n",
    "        x.size()  => (sample_size, x_dim)\n",
    "        mu.size() => (sample_size, mu_dim)\n",
    "        '''\n",
    "\n",
    "        r = F.relu(self.mu2r(mu))\n",
    "        phi = F.relu(self.xr2phi(torch.cat((x, r), 1)))\n",
    "        mu = self.muphi2mu(mu, phi)\n",
    "        o = F.relu(self.mu2o(mu))\n",
    "        o = self.log_softmax(o)\n",
    "        return o, mu\n",
    "    \n",
    "    def muphi2mu(self, mu, phi):\n",
    "        '''\n",
    "        すべての\\alphaについて、\\mu_t^{(\\alpha)} = \\alpha \\mu_{t-1}^{(\\alpha)} + (1-\\alpha) \\phi_t を同時に行う\n",
    "            A_mask:   Kronecker product of (A, ones(1, phi_dim)),   shape => (1, mu_dim)\n",
    "            phi_tile: Kronecker product of (ones(1, n_alpha), phi), shape => (sample_size, mu_dim)\n",
    "        '''\n",
    "        if self.gpu:\n",
    "            A_mask = kronecker_product(self.A, torch.ones(1, self.phi_dim).cuda(cuda_id))\n",
    "            phi_tile = kronecker_product(Variable(torch.ones(1, self.n_alpha).cuda(cuda_id)), phi)\n",
    "        else:\n",
    "            A_mask = kronecker_product(self.A, torch.ones(1, self.phi_dim))\n",
    "            phi_tile = kronecker_product(Variable(torch.ones(1, self.n_alpha)), phi)\n",
    "\n",
    "        # 要素積をとるためにA_maskをVariableに変換するが、A_maskは定数項なのでrequires_grad=Falseをつける\n",
    "        A_mask = Variable(A_mask, requires_grad=False)\n",
    "        mu = torch.mul(A_mask, mu) + torch.mul((1-A_mask), phi_tile)\n",
    "        return mu\n",
    "\n",
    "\n",
    "def kronecker_product(t1, t2):\n",
    "    t1_height, t1_width = t1.size()\n",
    "    t2_height, t2_width = t2.size()\n",
    "    out_height = t1_height * t2_height\n",
    "    out_width = t1_width * t2_width\n",
    "\n",
    "    tiled_t2 = t2.repeat(t1_height, t1_width)\n",
    "    expanded_t1 = (\n",
    "        t1.unsqueeze(2)\n",
    "          .unsqueeze(3)\n",
    "          .repeat(1, t2_height, t2_width, 1)\n",
    "          .view(out_height, out_width)\n",
    "    )\n",
    "\n",
    "    return expanded_t1 * tiled_t2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' パラメータの設定 '''\n",
    "\n",
    "x_dim = X_train.shape[2]\n",
    "phi_dim = 200\n",
    "r_dim = 60\n",
    "o_dim = np.unique(y_train).size\n",
    "A = torch.Tensor([0.0, 0.5, 0.9, 0.99]).view(1, -1).cuda(cuda_id)\n",
    "sru = SRU(x_dim, phi_dim, r_dim, o_dim, A)\n",
    "sru.cuda(cuda_id)\n",
    "\n",
    "batch_size = 100\n",
    "mu_dim = phi_dim * A.size()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' データセットの準備 その2 '''\n",
    "\n",
    "import torch.utils.data\n",
    "\n",
    "train = torch.utils.data.TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test = torch.utils.data.TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
    "testloader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' feedforwardの確認 '''\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "inputs, labels = dataiter.next()\n",
    "inputs, labels = Variable(inputs.cuda(cuda_id)), Variable(labels.cuda(cuda_id))\n",
    "\n",
    "# inputs.size => (seq_size, batch_size, n_features) に変形\n",
    "inputs = torch.transpose(inputs, 0, 1)\n",
    "\n",
    "# 隠れ変数の初期化\n",
    "mu = Variable(torch.rand(batch_size, mu_dim).cuda(cuda_id))\n",
    "\n",
    "# 確認\n",
    "x = inputs[0]\n",
    "outputs, mu = sru(x, mu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "''' 訓練 '''\n",
    "\n",
    "import time\n",
    "import math\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# 計算時間を表示させる\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "# NLLLossとlog_softmaxのoutputの組み合わせ\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(sru.parameters(), lr=1)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(1):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 1):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = Variable(inputs.cuda(cuda_id)), Variable(labels.cuda(cuda_id))\n",
    "        # inputs.size => (seq_size, batch_size, n_features) に変形\n",
    "        inputs = torch.transpose(inputs, 0, 1)\n",
    "        # 隠れ変数の初期化\n",
    "        mu = Variable(torch.rand(batch_size, mu_dim).cuda(cuda_id))\n",
    "        # 勾配の初期化\n",
    "        optimizer.zero_grad()\n",
    "        for x in inputs:\n",
    "            outputs, mu = sru(x, mu)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.data[0]\n",
    "\n",
    "        # 2000サンプルごとにlossを表示\n",
    "        if i * batch_size % 1000 == 0:\n",
    "            print('[%d, %5d] (%s) loss: %.5f' %\n",
    "                  (epoch + 1, i * batch_size, timeSince(start), running_loss / 1000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "        if i * batch_size % 20000 == 0:\n",
    "            break\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "1.00000e-03 *\n",
       "-0.0000 -0.0012 -0.0002  ...  -0.0020 -0.0028 -0.0021\n",
       " 0.0000  0.0518  0.0415  ...   0.0036  0.0047  0.0019\n",
       " 0.0000 -0.0760 -0.0139  ...   0.0016  0.0008 -0.0008\n",
       "          ...             ⋱             ...          \n",
       " 0.0000  0.0307  0.0079  ...  -0.0101 -0.0002  0.0069\n",
       "-0.0000 -0.1016 -0.0454  ...  -0.0029 -0.0176 -0.0139\n",
       " 0.0000  0.7504  0.2278  ...   0.0224  0.0398  0.0186\n",
       "[torch.cuda.FloatTensor of size 60x800 (GPU 0)]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# W^{(r)}の勾配の確認\n",
    "list(sru.parameters())[0].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the test images: 10 %\n"
     ]
    }
   ],
   "source": [
    "''' テスト '''\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for i, data in enumerate(trainloader, 1):\n",
    "    inputs, labels = data\n",
    "    inputs = Variable(inputs.cuda(cuda_id))\n",
    "    labels = labels.cuda(cuda_id)\n",
    "    # inputs.size => (seq_size, batch_size, n_features) に変形\n",
    "    inputs = torch.transpose(inputs, 0, 1)\n",
    "    # 隠れ変数の初期化\n",
    "    mu = Variable(torch.zeros(batch_size, mu_dim).cuda(cuda_id))\n",
    "\n",
    "    for x in inputs:\n",
    "        outputs, mu = sru(x, mu)\n",
    "    torch.t(outputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "    \n",
    "    if i * batch_size % 2000 == 0:\n",
    "        break\n",
    "\n",
    "print('Accuracy of the test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRUとの比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, hidden_layers=1):\n",
    "        super(GRU, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.hidden_layers = hidden_layers\n",
    "\n",
    "        self.gru = nn.GRU(input_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.log_softmax = nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        _, hn = self.gru(input, hidden)\n",
    "        ## from (1, N, hidden) to (N, hidden)\n",
    "        rearranged = hn.view(hn.size(1), hn.size(2))\n",
    "        out = self.linear(rearranged)\n",
    "        out = self.log_softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' パラメータの設定 '''\n",
    "\n",
    "input_size = X_train.shape[2]\n",
    "hidden_size = 200\n",
    "output_size = np.unique(y_train).size\n",
    "gru = GRU(input_size, hidden_size, output_size)\n",
    "gru.cuda(cuda_id)\n",
    "\n",
    "batch_size = 500\n",
    "train = torch.utils.data.TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test = torch.utils.data.TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
    "testloader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' feedforwardの確認 '''\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "inputs, labels = dataiter.next()\n",
    "inputs, labels = Variable(inputs.cuda(cuda_id)), Variable(labels.cuda(cuda_id))\n",
    "\n",
    "# inputs.size => (seq_len, batch_size, n_features) に変形\n",
    "inputs = torch.transpose(inputs, 0, 1)\n",
    "\n",
    "# 隠れ変数の初期化\n",
    "hidden = Variable(torch.randn(1, batch_size, hidden_size).cuda(cuda_id))\n",
    "\n",
    "# 確認\n",
    "outputs = gru(inputs, hidden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1000] (0m 0s) loss: 0.0046050\n",
      "[1,  2000] (0m 1s) loss: 0.0046088\n",
      "[1,  3000] (0m 2s) loss: 0.0046112\n",
      "[1,  4000] (0m 3s) loss: 0.0046084\n",
      "[1,  5000] (0m 4s) loss: 0.0046070\n",
      "[1,  6000] (0m 4s) loss: 0.0046052\n",
      "[1,  7000] (0m 5s) loss: 0.0046081\n",
      "[1,  8000] (0m 6s) loss: 0.0046110\n",
      "[1,  9000] (0m 7s) loss: 0.0046098\n",
      "[1, 10000] (0m 8s) loss: 0.0046092\n",
      "[1, 11000] (0m 8s) loss: 0.0046038\n",
      "[1, 12000] (0m 9s) loss: 0.0046083\n",
      "[1, 13000] (0m 10s) loss: 0.0046050\n",
      "[1, 14000] (0m 11s) loss: 0.0046149\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-7c0cbb74876a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# 1000サンプルごとにlossを表示\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "''' 訓練 '''\n",
    "\n",
    "# NLLLossとlog_softmaxのoutputの組み合わせ\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(sru.parameters(), lr=0.000001)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(1):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 1):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = Variable(inputs.cuda(cuda_id)), Variable(labels.cuda(cuda_id))\n",
    "        # inputs.size => (seq_size, batch_size, n_features) に変形\n",
    "        inputs = torch.transpose(inputs, 0, 1)\n",
    "        # 隠れ変数の初期化\n",
    "        hidden = Variable(torch.randn(1, batch_size, hidden_size).cuda(cuda_id))\n",
    "        # 勾配の初期化\n",
    "        optimizer.zero_grad()\n",
    "        outputs = gru(inputs, hidden)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.data[0]\n",
    "\n",
    "        # 1000サンプルごとにlossを表示\n",
    "        if i * batch_size % 1000 == 0:\n",
    "            print('[%d, %5d] (%s) loss: %.7f' %\n",
    "                  (epoch + 1, i * batch_size, timeSince(start), running_loss / 1000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "        if i * batch_size % 40000 == 0:\n",
    "            break\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_py35",
   "language": "python",
   "name": "tf_py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
